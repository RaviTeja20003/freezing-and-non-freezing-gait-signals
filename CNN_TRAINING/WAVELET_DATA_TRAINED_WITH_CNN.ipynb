{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators with InceptionV3 expected input size\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3583 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'D://PROJECTS/ALL_PROJECTS/FREEZING_AND_NON_FREEZING/wavelet_training/data/train',\n",
    "    target_size=(299, 299),  # Adjusted for InceptionV3\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    'D://PROJECTS/ALL_PROJECTS/FREEZING_AND_NON_FREEZING/wavelet_training/data/valid',\n",
    "    target_size=(299, 299),  # Adjusted for InceptionV3\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'D://PROJECTS/ALL_PROJECTS/FREEZING_AND_NON_FREEZING/wavelet_training/data/test',\n",
    "    target_size=(299, 299),  # Adjusted for InceptionV3\n",
    "    batch_size=16,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/322113877408650181', creation_time=1708515694937, experiment_id='322113877408650181', last_update_time=1708515694937, lifecycle_stage='active', name='FREEZING_AND_NON_FREEZING_SIGNAL_IMAGES_PROJECT', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_id=\"322113877408650181\")\n",
    " # set the experiment id from the mlflow website whenever new experiment is created \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 297, 297, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 148, 148, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 146, 146, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 73, 73, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 71, 71, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 35, 35, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 33, 33, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 16, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               33554944  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,009,153\n",
      "Trainable params: 34,009,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/23 08:20:27 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
      "2024/02/23 08:20:27 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.5484\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to cropped_model_changed_cnn_more_complex.h5\n",
      "224/224 [==============================] - 297s 1s/step - loss: 0.6929 - accuracy: 0.5484 - val_loss: 0.7014 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.5540\n",
      "Epoch 2: val_accuracy did not improve from 0.50000\n",
      "224/224 [==============================] - 273s 1s/step - loss: 0.6876 - accuracy: 0.5540 - val_loss: 0.7000 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.5540\n",
      "Epoch 3: val_accuracy did not improve from 0.50000\n",
      "224/224 [==============================] - 272s 1s/step - loss: 0.6880 - accuracy: 0.5540 - val_loss: 0.6985 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.5540\n",
      "Epoch 4: val_accuracy did not improve from 0.50000\n",
      "224/224 [==============================] - 281s 1s/step - loss: 0.6876 - accuracy: 0.5540 - val_loss: 0.6990 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.6877 - accuracy: 0.5540\n",
      "Epoch 5: val_accuracy did not improve from 0.50000\n",
      "224/224 [==============================] - 251s 1s/step - loss: 0.6877 - accuracy: 0.5540 - val_loss: 0.6990 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.5540\n",
      "Epoch 6: val_accuracy did not improve from 0.50000\n",
      "224/224 [==============================] - 255s 1s/step - loss: 0.6876 - accuracy: 0.5540 - val_loss: 0.6996 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.5540\n",
      "Epoch 7: val_accuracy did not improve from 0.50000\n",
      "224/224 [==============================] - 246s 1s/step - loss: 0.6880 - accuracy: 0.5540 - val_loss: 0.6977 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.6883 - accuracy: 0.5540\n",
      "Epoch 8: val_accuracy did not improve from 0.50000\n",
      "224/224 [==============================] - 246s 1s/step - loss: 0.6883 - accuracy: 0.5540 - val_loss: 0.6973 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.6873 - accuracy: 0.5540\n",
      "Epoch 9: val_accuracy did not improve from 0.50000\n",
      "224/224 [==============================] - 252s 1s/step - loss: 0.6873 - accuracy: 0.5540 - val_loss: 0.7015 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.5540\n",
      "Epoch 10: val_accuracy did not improve from 0.50000\n",
      "224/224 [==============================] - 254s 1s/step - loss: 0.6876 - accuracy: 0.5540 - val_loss: 0.6969 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "224/224 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.5540\n",
      "Epoch 11: val_accuracy did not improve from 0.50000\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "224/224 [==============================] - 252s 1s/step - loss: 0.6880 - accuracy: 0.5540 - val_loss: 0.6992 - val_accuracy: 0.5000\n",
      "Epoch 11: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/23 09:08:26 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: '>=' not supported between instances of 'slice' and 'int'\n",
      "2024/02/23 09:08:26 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ravit\\AppData\\Local\\Temp\\tmpezldfptq\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ravit\\AppData\\Local\\Temp\\tmpezldfptq\\model\\data\\model\\assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Updated CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(299, 299, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Initial Training\n",
    "with mlflow.start_run(run_name=\"cropped_changed_TO_WAVELET_DATA_with_batch_cnn_more_complex_without_finetuning\"):\n",
    "    model_checkpoint = ModelCheckpoint('cropped_model_changed_cnn_more_complex.h5', monitor='val_accuracy', \n",
    "                                       mode='max', save_best_only=True, verbose=1)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=10, verbose=1, \n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    history_st = model.fit(train_generator, validation_data=validation_generator, epochs=50, callbacks=[model_checkpoint, early_stopping, tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPACE_HACKATHON",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
