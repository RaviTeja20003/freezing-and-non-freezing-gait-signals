{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators with InceptionV3 expected input size\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3583 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'D://PROJECTS/ALL_PROJECTS/FREEZING_AND_NON_FREEZING/wavelet_training/data/train',\n",
    "    target_size=(299, 299),  # Adjusted for InceptionV3\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    'D://PROJECTS/ALL_PROJECTS/FREEZING_AND_NON_FREEZING/wavelet_training/data/valid',\n",
    "    target_size=(299, 299),  # Adjusted for InceptionV3\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'D://PROJECTS/ALL_PROJECTS/FREEZING_AND_NON_FREEZING/wavelet_training/data/test',\n",
    "    target_size=(299, 299),  # Adjusted for InceptionV3\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using InceptionV3\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding custom layers on top of InceptionV3\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # New FC layer, random init\n",
    "predictions = Dense(1, activation='sigmoid')(x)  # New softmax layer\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/322113877408650181', creation_time=1708515694937, experiment_id='322113877408650181', last_update_time=1708515694937, lifecycle_stage='active', name='FREEZING_AND_NON_FREEZING_SIGNAL_IMAGES_PROJECT', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_id=\"322113877408650181\")\n",
    " # set the experiment id from the mlflow website whenever new experiment is created \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/23 02:01:37 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
      "2024/02/23 02:01:37 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.7689 - accuracy: 0.5359\n",
      "Epoch 1: val_accuracy improved from -inf to 0.45500, saving model to cropped_model_changed_inceptionv3.h5\n",
      "112/112 [==============================] - 82s 556ms/step - loss: 0.7689 - accuracy: 0.5359 - val_loss: 0.7031 - val_accuracy: 0.4550\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5414\n",
      "Epoch 2: val_accuracy improved from 0.45500 to 0.50750, saving model to cropped_model_changed_inceptionv3.h5\n",
      "112/112 [==============================] - 61s 538ms/step - loss: 0.6927 - accuracy: 0.5414 - val_loss: 0.6917 - val_accuracy: 0.5075\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6868 - accuracy: 0.5484\n",
      "Epoch 3: val_accuracy did not improve from 0.50750\n",
      "112/112 [==============================] - 58s 511ms/step - loss: 0.6868 - accuracy: 0.5484 - val_loss: 0.6962 - val_accuracy: 0.4975\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6834 - accuracy: 0.5560\n",
      "Epoch 4: val_accuracy improved from 0.50750 to 0.54000, saving model to cropped_model_changed_inceptionv3.h5\n",
      "112/112 [==============================] - 58s 517ms/step - loss: 0.6834 - accuracy: 0.5560 - val_loss: 0.6854 - val_accuracy: 0.5400\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6817 - accuracy: 0.5641\n",
      "Epoch 5: val_accuracy improved from 0.54000 to 0.61000, saving model to cropped_model_changed_inceptionv3.h5\n",
      "112/112 [==============================] - 58s 514ms/step - loss: 0.6817 - accuracy: 0.5641 - val_loss: 0.6728 - val_accuracy: 0.6100\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.5654\n",
      "Epoch 6: val_accuracy improved from 0.61000 to 0.61500, saving model to cropped_model_changed_inceptionv3.h5\n",
      "112/112 [==============================] - 73s 645ms/step - loss: 0.6811 - accuracy: 0.5654 - val_loss: 0.6670 - val_accuracy: 0.6150\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6763 - accuracy: 0.5752\n",
      "Epoch 7: val_accuracy did not improve from 0.61500\n",
      "112/112 [==============================] - 74s 654ms/step - loss: 0.6763 - accuracy: 0.5752 - val_loss: 0.6679 - val_accuracy: 0.5825\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.5445\n",
      "Epoch 8: val_accuracy did not improve from 0.61500\n",
      "112/112 [==============================] - 67s 595ms/step - loss: 0.6872 - accuracy: 0.5445 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6776 - accuracy: 0.5769\n",
      "Epoch 9: val_accuracy improved from 0.61500 to 0.66500, saving model to cropped_model_changed_inceptionv3.h5\n",
      "112/112 [==============================] - 70s 626ms/step - loss: 0.6776 - accuracy: 0.5769 - val_loss: 0.6606 - val_accuracy: 0.6650\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6781 - accuracy: 0.5735\n",
      "Epoch 10: val_accuracy did not improve from 0.66500\n",
      "112/112 [==============================] - 60s 531ms/step - loss: 0.6781 - accuracy: 0.5735 - val_loss: 0.6570 - val_accuracy: 0.6600\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6748 - accuracy: 0.5761\n",
      "Epoch 11: val_accuracy did not improve from 0.66500\n",
      "112/112 [==============================] - 64s 568ms/step - loss: 0.6748 - accuracy: 0.5761 - val_loss: 0.6629 - val_accuracy: 0.5625\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6725 - accuracy: 0.5816\n",
      "Epoch 12: val_accuracy did not improve from 0.66500\n",
      "112/112 [==============================] - 72s 636ms/step - loss: 0.6725 - accuracy: 0.5816 - val_loss: 0.6582 - val_accuracy: 0.5950\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6746 - accuracy: 0.5755\n",
      "Epoch 13: val_accuracy did not improve from 0.66500\n",
      "112/112 [==============================] - 71s 630ms/step - loss: 0.6746 - accuracy: 0.5755 - val_loss: 0.6484 - val_accuracy: 0.6425\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.5844\n",
      "Epoch 14: val_accuracy improved from 0.66500 to 0.71000, saving model to cropped_model_changed_inceptionv3.h5\n",
      "112/112 [==============================] - 71s 634ms/step - loss: 0.6707 - accuracy: 0.5844 - val_loss: 0.6354 - val_accuracy: 0.7100\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6689 - accuracy: 0.5956\n",
      "Epoch 15: val_accuracy did not improve from 0.71000\n",
      "112/112 [==============================] - 88s 785ms/step - loss: 0.6689 - accuracy: 0.5956 - val_loss: 0.6427 - val_accuracy: 0.6900\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6750 - accuracy: 0.5763\n",
      "Epoch 16: val_accuracy did not improve from 0.71000\n",
      "112/112 [==============================] - 74s 655ms/step - loss: 0.6750 - accuracy: 0.5763 - val_loss: 0.6744 - val_accuracy: 0.5250\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6686 - accuracy: 0.5903\n",
      "Epoch 17: val_accuracy did not improve from 0.71000\n",
      "112/112 [==============================] - 71s 628ms/step - loss: 0.6686 - accuracy: 0.5903 - val_loss: 0.6417 - val_accuracy: 0.6925\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6720 - accuracy: 0.5763\n",
      "Epoch 18: val_accuracy did not improve from 0.71000\n",
      "112/112 [==============================] - 63s 556ms/step - loss: 0.6720 - accuracy: 0.5763 - val_loss: 0.6308 - val_accuracy: 0.6500\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6716 - accuracy: 0.5808\n",
      "Epoch 19: val_accuracy did not improve from 0.71000\n",
      "112/112 [==============================] - 74s 661ms/step - loss: 0.6716 - accuracy: 0.5808 - val_loss: 0.6472 - val_accuracy: 0.6250\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6718 - accuracy: 0.5872\n",
      "Epoch 20: val_accuracy did not improve from 0.71000\n",
      "112/112 [==============================] - 72s 637ms/step - loss: 0.6718 - accuracy: 0.5872 - val_loss: 0.6629 - val_accuracy: 0.5600\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6764 - accuracy: 0.5772\n",
      "Epoch 21: val_accuracy did not improve from 0.71000\n",
      "112/112 [==============================] - 75s 668ms/step - loss: 0.6764 - accuracy: 0.5772 - val_loss: 0.6299 - val_accuracy: 0.6800\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6727 - accuracy: 0.5886\n",
      "Epoch 22: val_accuracy improved from 0.71000 to 0.72500, saving model to cropped_model_changed_inceptionv3.h5\n",
      "112/112 [==============================] - 74s 661ms/step - loss: 0.6727 - accuracy: 0.5886 - val_loss: 0.6227 - val_accuracy: 0.7250\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6702 - accuracy: 0.5908\n",
      "Epoch 23: val_accuracy did not improve from 0.72500\n",
      "112/112 [==============================] - 78s 692ms/step - loss: 0.6702 - accuracy: 0.5908 - val_loss: 0.7347 - val_accuracy: 0.4975\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6663 - accuracy: 0.5839\n",
      "Epoch 24: val_accuracy did not improve from 0.72500\n",
      "112/112 [==============================] - 80s 707ms/step - loss: 0.6663 - accuracy: 0.5839 - val_loss: 0.6288 - val_accuracy: 0.6400\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6691 - accuracy: 0.5872\n",
      "Epoch 25: val_accuracy did not improve from 0.72500\n",
      "112/112 [==============================] - 95s 846ms/step - loss: 0.6691 - accuracy: 0.5872 - val_loss: 0.6294 - val_accuracy: 0.6775\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6706 - accuracy: 0.5908\n",
      "Epoch 26: val_accuracy did not improve from 0.72500\n",
      "112/112 [==============================] - 90s 798ms/step - loss: 0.6706 - accuracy: 0.5908 - val_loss: 0.6297 - val_accuracy: 0.6700\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.6056\n",
      "Epoch 27: val_accuracy did not improve from 0.72500\n",
      "112/112 [==============================] - 98s 876ms/step - loss: 0.6636 - accuracy: 0.6056 - val_loss: 0.6311 - val_accuracy: 0.6325\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6565 - accuracy: 0.6157\n",
      "Epoch 28: val_accuracy did not improve from 0.72500\n",
      "112/112 [==============================] - 88s 779ms/step - loss: 0.6565 - accuracy: 0.6157 - val_loss: 0.6376 - val_accuracy: 0.6175\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6669 - accuracy: 0.5989\n",
      "Epoch 29: val_accuracy did not improve from 0.72500\n",
      "112/112 [==============================] - 56s 494ms/step - loss: 0.6669 - accuracy: 0.5989 - val_loss: 0.6293 - val_accuracy: 0.6500\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6677 - accuracy: 0.5939\n",
      "Epoch 30: val_accuracy did not improve from 0.72500\n",
      "112/112 [==============================] - 61s 540ms/step - loss: 0.6677 - accuracy: 0.5939 - val_loss: 0.6630 - val_accuracy: 0.5525\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6664 - accuracy: 0.5970\n",
      "Epoch 31: val_accuracy did not improve from 0.72500\n",
      "112/112 [==============================] - 60s 537ms/step - loss: 0.6664 - accuracy: 0.5970 - val_loss: 0.6617 - val_accuracy: 0.5625\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.6635 - accuracy: 0.5914\n",
      "Epoch 32: val_accuracy did not improve from 0.72500\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "112/112 [==============================] - 62s 551ms/step - loss: 0.6635 - accuracy: 0.5914 - val_loss: 0.6468 - val_accuracy: 0.6125\n",
      "Epoch 32: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/23 02:39:54 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: '>=' not supported between instances of 'slice' and 'int'\n",
      "2024/02/23 02:39:54 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ravit\\AppData\\Local\\Temp\\tmpti5s2ckw\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\ravit\\AppData\\Local\\Temp\\tmpti5s2ckw\\model\\data\\model\\assets\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.tensorflow.autolog()\n",
    "# set the experiment id\n",
    "\n",
    "#Initial Training\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"cropped_changed_TO_WAVELET_DATA_with_batch_inceptionv3_without_finetuning\"):\n",
    "    # Additionally, use ModelCheckpoint to save the best model based on validation accuracy\n",
    "     \n",
    "    model_checkpoint = ModelCheckpoint('cropped_model_changed_inceptionv3.h5', monitor='val_accuracy', \n",
    "                                   mode='max', save_best_only=True, verbose=1)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=10, verbose=1, \n",
    "                               restore_best_weights=True)\n",
    "\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history_st = model.fit(train_generator, validation_data=validation_generator, epochs=50, callbacks=[model_checkpoint, early_stopping, tensorboard_callback])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_st.history['accuracy'], label='Train')\n",
    "plt.plot(history_st.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_st.history['loss'], label='Train')\n",
    "plt.plot(history_st.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Log the plot file to MLflow\n",
    "mlflow.log_artifact(\"D://PROJECTS/ALL_PROJECTS/EYE-CLASSIFICATION/INCEPTION_TRAINING/output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the fine-tuned model\n",
    "loaded_model = load_model(\"D://PROJECTS/ALL_PROJECTS/EYE-CLASSIFICATION/INCEPTION_TRAINING/best_model_inceptionv3.h5\")\n",
    "# Assuming 'model' is your trained model for prediction and evaluation\n",
    "predictions = loaded_model.predict(test_generator)\n",
    "y_pred = np.where(predictions > 0.5, 1, 0).reshape(-1)  # Adjust threshold as needed\n",
    "y_true = test_generator.classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_true, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Logging metrics to MLflow\n",
    "mlflow.log_metric(\"accuracy\", accuracy)\n",
    "mlflow.log_metric(\"recall\", recall)\n",
    "mlflow.log_metric(\"f1_score\", f1)\n",
    "mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report and confusion matrix\n",
    "report = classification_report(y_true, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "print(report_df)\n",
    "report_df.to_csv(\"classification_report.csv\")\n",
    "mlflow.log_artifact(\"classification_report.csv\", artifact_path='metrics')\n",
    "mlflow.log_artifact(\"best_model_inceptionv3.h5\",artifact_path='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", ax=ax, cmap='Blues')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "mlflow.log_artifact(\"confusion_matrix.png\", artifact_path='metrics')\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPACE_HACKATHON",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
